## 深度学习

---

1. **对目前人工智能行业的了解**

> 现在几乎每个行业都在用AI，从我们用的智能手机助手到自动驾驶汽车，再到医生用来帮助诊断疾病的工具。目前，机器学习和深度学习是推动这一领域进步的核心技术，它们使得计算机能够处理和分析大量数据，以学习和模拟复杂的人类行为和决策过程。
>
> 在具体的应用方面，人工智能技术正在重新定义许多行业的运作方式。例如，在医疗领域，通过深度学习模型分析医疗影像，可以协助医生更准确地诊断疾病。在金融服务行业，人工智能被用于风险评估、交易监控以及为客户提供个性化的投资建议。
>
> 随着人工智能技术的不断成熟和应用范围的扩大，我们也面临着一系列挑战，特别是在伦理和隐私保护方面。隐私保护、数据安全以及算法偏见是当前亟需解决的问题。此外，如何提高算法的透明度和可解释性，也是确保人工智能健康发展的关键。

1. **大语言模型的Transformer架构编码解码内部怎样的？（重点！）**

> Transformer架构是一种重要的深度学习模型，广泛应用于自然语言处理(NLP)领域。其核心思想是利用自注意力(self-attention)机制来捕捉输入数据的全局依赖关系。Transformer包含两大部分：编码器(encoder)和解码器(decoder)。
>
> - **编码器**：由多个相同的层堆叠而成，每层主要由两个子层构成，一个是多头自注意力机制(multi-head self-attention mechanism)，另一个是简单的位置全连接前馈网络(position-wise fully connected feed-forward network)。每个子层周围都有一个残差连接(residual connection)跟随着层归一化(layer normalization)。
> - **解码器**：解码器也由多个相同的层堆叠而成，但除了编码器层中的两个子层之外，每个解码器层还插入了一个第三个子层，用于对编码器的输出进行注意力操作，即编码器-解码器注意力(encoder-decoder attention)机制。解码器同样采用了残差连接和层归一化。
>
> 编码器和解码器的不同之处在于解码器的自注意力层还包含一个遮蔽机制(masking)，以防止未来位置的信息流入当前位置，确保预测仅依赖于已知的输出。

1. **模型的压缩与加速方法**

> 随着深度学习模型在各个领域的广泛应用，模型越来越大，计算资源的需求也随之增加。为了能够让这些模型在资源受限的环境中，如移动设备和嵌入式系统上高效运行，模型的压缩与加速就显得尤为重要。
>
> 1. **参数剪纸**：这种方法通过移除模型中的一些不重要的参数（例如，权重较小，对模型输出影响不大的参数）来减小模型大小和计算复杂度。参数剪枝后的模型在实际运行时可以跳过这些被剪枝的连接，从而加速推理过程。
> 2. **减少每个权重的比特数**：例如从32位浮点数降低到8位整数，可以显著减少模型的大小，并加快计算速度。
> 3. **知识蒸馏**：知识蒸馏是一种模型压缩技术，它通过训练一个小的“学生”模型去模拟一个大的“老师”模型的行为。通过这种方式，小模型能够在保持性能的同时，减少计算资源的需求。
> 4. **将参数矩阵分解**：通过矩阵分解技术，将大的权重矩阵分解成几个小的矩阵的乘积，可以减少模型的参数数量，从而加速计算过程。

1. **残差网络的优势？为什么会梯度消失？**

> 首先，让我们谈谈残差网络的优势。残差网络通过引入残差块（Residual Blocks）的概念，成功解决了深度神经网络训练过程中的梯度消失和梯度爆炸问题，从而允许我们构建更深的网络模型。每个残差块包含一个或多个权重层，以及一个跳跃连接，该连接允许部分输入直接跳过这些层。这种结构的主要优势包括：
>
> 1. **解决梯度消失/爆炸问题**：通过跳跃连接，残差块允许梯度直接流过，这意味着即使在非常深的网络中，信息也能够有效地传递，从而减轻梯度消失或爆炸的风险。
> 2. **加速训练过程**：残差网络的这种设计还有助于加快训练速度，因为它改善了信息在网络中的流动。
>
> 在深度神经网络中，梯度消失主要是由于在反向传播过程中连续乘以小于1的权重导致的。随着网络层次的加深，这些小数的连乘效果会使得靠近输入层的梯度变得非常小，甚至趋近于零。这会导致网络早期层的权重更新缓慢，难以训练深层网络。

1. **你了解几种损失函数？几种传递函数？**

> 损失函数是衡量模型预测值与真实值之间差异的指标，在模型训练过程中通过最小化损失函数来优化模型参数。不同类型的任务和模型可能会选择不同的损失函数。
>
> 1. **均方误差（Mean Squared Error, MSE）**：常用于回归任务，计算预测值与真实值差的平方的平均值。
> 2. **交叉熵损失（Cross-Entropy Loss）**：常用于分类任务，特别是二分类或多分类问题。它衡量的是模型预测的概率分布与真实标签的概率分布之间的差异。
> 3. **合页损失（Hinge Loss）**：常用于支持向量机（SVM）中的分类问题。它旨在增加正确分类样本和错误分类样本之间的边距。
> 4. **对数损失（Logistic Loss）**：也是一种用于二分类的损失函数，与交叉熵损失类似，它在逻辑回归模型中特别常见。
>
> 激活函数：
>
> 1. **ReLU（Rectified Linear Unit）**：目前最常用的激活函数之一，它的公式是`f(x) = max(0, x)`。ReLU函数对正输入保持不变，对负输入则将其置为0。
> 2. **Sigmoid**：将输入压缩到0和1之间，形式为`f(x) = 1 / (1 + exp(-x))`。它常用于输出层，用于二分类问题。
> 3. **Tanh（双曲正切函数）**：与Sigmoid相似，但输出范围在-1和1之间。形式为`f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))`。
> 4. **Softmax**：Softmax函数将一个向量压缩成一个概率分布，其中每个元素的范围都在0到1之间，并且所有元素的和为1。它常用于多分类问题的输出层。

1. 你了解聚类算法有哪些？（K均值）原理？

   > **K-means(K均值)**，**谱聚类（Spectral clustering）**：通过利用数据的谱（即特征值）进行聚类，特别适合于发现复杂形状的簇。
   >
   > K-means算法：
   >
   > 采用**距离**（sklearn里面用的是欧氏距离，还有曼哈顿距离，余弦相似度）作为相似性的评价指标，即认为两个对象的距离越近，其相似度就越大。该算法认为类簇是由距离靠近的对象组成的，因此把得到紧凑且独立的簇作为最终目标。
   >
   > ​	1、首先确定一个k值，即我们希望将数据集经过聚类得到k个集合。
   >
   > ​	2、从数据集中随机选择k个数据点作为质心。
   >
   > ​	3、对数据集中每一个点，计算其与每一个质心的距离（如欧式距离），离哪个质心近，就划分到那个质心所属的集合。
   >
   > ​	4、把所有数据归好集合后，一共有k个集合。然后重新计算每个集合的质心。
   >
   > ​	5、如果新计算出来的质心和原来的质心之间的距离小于某一个设置的阈值（表示重新计算的质心的位置变化不大，趋于稳定，或者说收敛），我们可以认为聚类已经达到期望的结果，算法终止。
   >
   > ​	6、如果新质心和原质心距离变化很大，需要迭代3~5步骤。
   >
   > [Kmeans算法 动画演示_聚类算法 k-means动画演示-CSDN博客](https://blog.csdn.net/chekongfu/article/details/104936655)
   >
   > [K-means聚类及距离度量方法小结_kmeans距离计算-CSDN博客](https://blog.csdn.net/qq_38563206/article/details/120940393)

   K-means优缺点及优化：

   > [【机器学习】K-Means算法优化_kmeans算法优化-CSDN博客](https://blog.csdn.net/qq_46092061/article/details/119044970)

   

2. 常用的滤波器？（高斯滤波）原理？（选择像素点周围部分像素进行均方差等操作消除噪声）

3. 主成分分析与相关性分析的区别？（忘了）

---

1. 多头注意力是怎么合并的
2. 多任务学习的损失函数
3. Batch Normalization 的细节

---

1. 先是问了知道transformer的架构如何设计的么？我答理解的。遂让我介绍下transformer的block的结构，我巴拉巴拉，然后继续问编码器和解码器的细节，编码器的position是用的什么函数，解码器和编码器的不同之处，解码器mask是怎么设计的。有的我答出来了，有的确实忘了，比如position的函数我只回答说记得是用了两个三角函数。
2. 然后被拷打了一下项目，让做题。手撕了一道simple的算法题，两数之和，秒了。然后又被追问三数之和怎么办，我讲了下在两数之和基础上的思路，被说能不能优化一下时间复杂度，提醒我可以用二分，但本人实在太笨，没想出来，被面试官安慰说没事。

---

1. 针对项目问了个问题，如果数据增大，效果会更好吗，有什么改进和想法?
2. 手撕线性回归

---

1. 手搓multi-head attn
2. L1和L2有什么区别，各自的优缺点？
3. 口述将一张图片实现90度旋转的思路
4.  self-attention剖析：公式+意义，顺便问了下缩放因子是干嘛的

---

1. Transformer结构介绍
2. 介绍多头注意力机制
3. BN和LN的区别，为什么transformer要用LN
4. 增加非线性是在哪个部分
5. 了不了解vision transformer…等做cv的transformer
6. KNN介绍，怎么迭代的
7. Kmeans介绍
8.  如果在使用knn，kmeans的时候，有噪音干扰，怎么处理

---

1. 机器学习中常见的回归和分类算法
2. 逻辑回归的损失函数
3. 随机森林和XGBoost的区别
4. 主成分分析的原理

---

1、xgboost和lgbm的区别是什么？

​    特征浮点分箱为直方图加速。

2、kmeans的算法原理是什么？

​    任取几个点作为聚类中心；迭代n轮：先给每个点找距离最近的中心，然后将中心作为变量，优化目标函数（mse），中心位置和每个样本所属类别交替迭代。

3、DBScan和层次聚类的原理是什么？

​     

4、transformer的原理是什么？

​    

5、大模型微调的流程是什么？

6、lora和stable diffusion怎么用？

7、NLP大模型怎么开发？

​    

8、系统辨识的算法有哪些?

9、快速排序怎么写？非递归形式怎么写?

​     

10、怎么判定一个点在多边形内部？

---

一开始让自我介绍 我说对机器学习有比较深入的了解 面试官说在我面前说了解 看来你很自信啊hhh 其实当时我没想那么多hhh

第一个问题就是如何解决过拟合和欠拟合 让结合具体的模型来说

问了交叉验证

L1正则化 L2正则化

问了如何看数据统计效果（具体问题记不清了 当时也没有理解 又追问了这是什么意思） 后面面试官看我做过多目标优化的项目 就说你应该做过呀 我从模型改进前后的效果评价去答了 面试官补充了一些比如看AUC值 感觉是从分类模型的效果评价去答的

是否了解基于协同过滤的推荐算法 这块确实不了解 就过了

知道因果推断模型有哪些方法 这块不了解 答得很模糊 

一个开放题 大概是如何看美团平台上不同人群的特征喜好 实话实说以前没做过真实场景 这块我从聚类的角度答得 提到了kmeans聚类 文本聚类（词袋模型、tf-idf、word2vec、bm25） 顺带着把大模型 bert transformer 也过了一下

说一个之前的项目 怎么做的优化 （说了一个合成优化的项目 答得还比较流利 感觉面试官也比较满意）

然后开始写编程题 出了一道“找零问题”（有1元、4元、5元的硬币，找到满足15元的最少硬币数量）

一开始想用穷举法 但没写出来 17分钟之后 面试官说你写的不能涵盖所有情况 我提到可以用动态规划法做这个题 然后跟面试官交流了一下做法

---

然后问了有监督学习了解哪些 说了决策树 随机森林 逻辑回归 SVM等 

问了随机森林的原理和它的作用

问了三种决策树的信息划分准则

问了集成学习中的bagging和boosting算法以及两种的区别，这里我说随机森林是boosting算法，又是大雷，感觉我说完后面试官已经不想理我了hhh。我问是哪说的不对吗 他说你了解xgboost算法吗 了解 那xgboost算法和随机森林的原理是一样的吗 我：应该不一样把~

统计学中的P值是什么含义 如何通俗地像运营和内容的同学解释

怎样理解AUC值（注意 是理解）

问了整数规划的方法 给了一个场景 为美团平台上的所有用户发放优惠券 应该如何分配 是的收益最大 优惠券面额应该是以整数为主

让说之前做过的机器学习项目 做分类模型的时候需要注意什么（当时真是脑子抽了 交叉验证 smote采样这些都没答出来）

问梯度提升决策树的原理（这个没了解过 后面发现就是GBDT 我嘞个豆）

---

